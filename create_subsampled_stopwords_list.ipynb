{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNG3Nm9CHp62FMWwT+FFfsP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isabelklint/scrapers/blob/main/create_subsampled_stopwords_list.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "import math\n",
        "from collections import Counter\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Read in corpus from CSV file\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/corpus.csv\")\n",
        "\n",
        "# Extract text from corpus DataFrame\n",
        "corpus = df['text']\n",
        "\n",
        "def generate_stopword_list(corpus, frequency_threshold, probability_threshold):\n",
        "    \"\"\"\n",
        "    Generate a stop word list using subsampling.\n",
        "    \n",
        "    Args:\n",
        "    corpus (list): List of documents in the corpus.\n",
        "    frequency_threshold (int): Frequency threshold for subsampling.\n",
        "    probability_threshold (float): Probability threshold for subsampling.\n",
        "    \n",
        "    Returns:\n",
        "    list: List of stop words.\n",
        "    \"\"\"\n",
        "    # Count word frequencies in the corpus\n",
        "    word_counts = Counter()\n",
        "    for document in corpus:\n",
        "        word_counts.update(document.split())\n",
        "    \n",
        "    # Subsample words based on frequency and probability thresholds\n",
        "    stopword_list = []\n",
        "    for word, count in word_counts.items():\n",
        "        if count > frequency_threshold:\n",
        "            subsampling_probability = 1 - math.sqrt(frequency_threshold / count)\n",
        "            if subsampling_probability > probability_threshold:\n",
        "                stopword_list.append(word)\n",
        "    \n",
        "    return stopword_list\n",
        "\n",
        "# Generate stopword list using subsampling\n",
        "stopword_list = generate_stopword_list(corpus, frequency_threshold=2, probability_threshold=0.5)\n",
        "\n",
        "# Save stopword list as CSV file\n",
        "with open('/content/drive/My Drive/amharic_subsampled_stop_words_2023.csv', 'w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(stopword_list)\n"
      ],
      "metadata": {
        "id": "_jJhO0KFmpJw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}